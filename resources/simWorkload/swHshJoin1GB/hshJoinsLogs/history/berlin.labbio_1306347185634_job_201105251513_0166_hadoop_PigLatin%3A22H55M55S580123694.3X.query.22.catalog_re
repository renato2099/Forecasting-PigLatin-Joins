Meta VERSION="1" .
Job JOBID="job_201105251513_0166" JOBNAME="PigLatin:22H55M55S580123694\.3X\.query\.22\.catalog_returns\.warehouse\.15\.1\.pig" USER="hadoop" SUBMIT_TIME="1306385434588" JOBCONF="hdfs://berlin\.labbio:54310/mnt/hadoop-tmp/dir/hadoop-hadoop/mapred/system/job_201105251513_0166/job\.xml" .
Job JOBID="job_201105251513_0166" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201105251513_0166" LAUNCH_TIME="1306385434853" TOTAL_MAPS="2" TOTAL_REDUCES="2" JOB_STATUS="PREP" .
Task TASKID="task_201105251513_0166_m_000003" TASK_TYPE="SETUP" START_TIME="1306385435247" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201105251513_0166_m_000003" TASK_ATTEMPT_ID="attempt_201105251513_0166_m_000003_0" START_TIME="1306384457162" TRACKER_NAME="tracker_moscou\.labbio:localhost/127\.0\.0\.1:36922" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201105251513_0166_m_000003" TASK_ATTEMPT_ID="attempt_201105251513_0166_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1306384458247" HOSTNAME="/default-rack/moscou\.labbio" STATE_STRING="setup" COUNTERS="{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)]}" .
Task TASKID="task_201105251513_0166_m_000003" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1306385438252" COUNTERS="{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)]}" .
Job JOBID="job_201105251513_0166" JOB_STATUS="RUNNING" .
Task TASKID="task_201105251513_0166_m_000000" TASK_TYPE="MAP" START_TIME="1306385438253" SPLITS="/default-rack/berlin\.labbio,/default-rack/moscou\.labbio,/default-rack/damasco\.labbio" .
Task TASKID="task_201105251513_0166_m_000001" TASK_TYPE="MAP" START_TIME="1306385439578" SPLITS="/default-rack/berlin\.labbio,/default-rack/damasco\.labbio,/default-rack/moscou\.labbio" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201105251513_0166_m_000000" TASK_ATTEMPT_ID="attempt_201105251513_0166_m_000000_0" START_TIME="1306384459862" TRACKER_NAME="tracker_moscou\.labbio:localhost/127\.0\.0\.1:36922" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201105251513_0166_m_000000" TASK_ATTEMPT_ID="attempt_201105251513_0166_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1306384464339" HOSTNAME="/default-rack/moscou\.labbio" STATE_STRING="" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(21378371)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(2149333)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(144067)][(SPILLED_RECORDS)(Spilled Records)(144067)][(MAP_OUTPUT_BYTES)(Map output bytes)(1861131)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(144067)]}" .
Task TASKID="task_201105251513_0166_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1306385444277" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(21378371)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(2149333)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(144067)][(SPILLED_RECORDS)(Spilled Records)(144067)][(MAP_OUTPUT_BYTES)(Map output bytes)(1861131)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(144067)]}" .
Task TASKID="task_201105251513_0166_r_000000" TASK_TYPE="REDUCE" START_TIME="1306385444278" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201105251513_0166_m_000001" TASK_ATTEMPT_ID="attempt_201105251513_0166_m_000001_0" START_TIME="1306385440034" TRACKER_NAME="tracker_berlin\.labbio:localhost/127\.0\.0\.1:38958" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201105251513_0166_m_000001" TASK_ATTEMPT_ID="attempt_201105251513_0166_m_000001_0" TASK_STATUS="FAILED" FINISH_TIME="1306385442580" HOSTNAME="berlin\.labbio" ERROR="Error: java\.lang\.ClassNotFoundException: org\.apache\.hadoop\.hdfs\.protocol\.LocatedBlocks
	at java\.net\.URLClassLoader$1\.run(URLClassLoader\.java:214)
	at java\.security\.AccessController\.doPrivileged(Native Method)
	at java\.net\.URLClassLoader\.findClass(URLClassLoader\.java:205)
	at java\.lang\.ClassLoader\.loadClass(ClassLoader\.java:321)
	at sun\.misc\.Launcher$AppClassLoader\.loadClass(Launcher\.java:294)
	at java\.lang\.ClassLoader\.loadClass(ClassLoader\.java:266)
	at java\.lang\.Class\.getDeclaredMethods0(Native Method)
	at java\.lang\.Class\.privateGetDeclaredMethods(Class\.java:2444)
	at java\.lang\.Class\.privateGetPublicMethods(Class\.java:2564)
	at java\.lang\.Class\.getMethods(Class\.java:1427)
	at sun\.misc\.ProxyGenerator\.generateClassFile(ProxyGenerator\.java:426)
	at sun\.misc\.ProxyGenerator\.generateProxyClass(ProxyGenerator\.java:323)
	at java\.lang\.reflect\.Proxy\.getProxyClass(Proxy\.java:518)
	at java\.lang\.reflect\.Proxy\.newProxyInstance(Proxy\.java:598)
	at org\.apache\.hadoop\.ipc\.RPC\.getProxy(RPC\.java:355)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.createRPCNamenode(DFSClient\.java:106)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.<init>(DFSClient\.java:207)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.<init>(DFSClient\.java:170)
	at org\.apache\.hadoop\.hdfs\.DistributedFileSystem\.initialize(DistributedFileSystem\.java:82)
	at org\.apache\.hadoop\.fs\.FileSystem\.createFileSystem(FileSystem\.java:1378)
	at org\.apache\.hadoop\.fs\.FileSystem\.access$200(FileSystem\.java:66)
	at org\.apache\.hadoop\.fs\.FileSystem$Cache\.get(FileSystem\.java:1390)
	at org\.apache\.hadoop\.fs\.FileSystem\.get(FileSystem\.java:196)
	at org\.apache\.hadoop\.fs\.FileSystem\.get(FileSystem\.java:95)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:168)
Caused by: java\.io\.EOFException: Detect premature EOF
	at sun\.misc\.Resource\.getBytes(Resource\.java:131)
	at java\.net\.URLClassLoader\.defineClass(URLClassLoader\.java:273)
	at java\.net\.URLClassLoader\.access$000(URLClassLoader\.java:73)
	at java\.net\.URLClassLoader$1\.run(URLClassLoader\.java:212)
	\.\.\. 24 more
,Error: java\.lang\.ClassNotFoundException: org\.apache\.hadoop\.hdfs\.protocol\.LocatedBlocks
	at java\.net\.URLClassLoader$1\.run(URLClassLoader\.java:214)
	at java\.security\.AccessController\.doPrivileged(Native Method)
	at java\.net\.URLClassLoader\.findClass(URLClassLoader\.java:205)
	at java\.lang\.ClassLoader\.loadClass(ClassLoader\.java:321)
	at sun\.misc\.Launcher$AppClassLoader\.loadClass(Launcher\.java:294)
	at java\.lang\.ClassLoader\.loadClass(ClassLoader\.java:266)
	at java\.lang\.Class\.getDeclaredMethods0(Native Method)
	at java\.lang\.Class\.privateGetDeclaredMethods(Class\.java:2444)
	at java\.lang\.Class\.privateGetPublicMethods(Class\.java:2564)
	at java\.lang\.Class\.getMethods(Class\.java:1427)
	at sun\.misc\.ProxyGenerator\.generateClassFile(ProxyGenerator\.java:426)
	at sun\.misc\.ProxyGenerator\.generateProxyClass(ProxyGenerator\.java:323)
	at java\.lang\.reflect\.Proxy\.getProxyClass(Proxy\.java:518)
	at java\.lang\.reflect\.Proxy\.newProxyInstance(Proxy\.java:598)
	at org\.apache\.hadoop\.ipc\.RPC\.getProxy(RPC\.java:355)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.createRPCNamenode(DFSClient\.java:106)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.<init>(DFSClient\.java:207)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.<init>(DFSClient\.java:170)
	at org\.apache\.hadoop\.hdfs\.DistributedFileSystem\.initialize(DistributedFileSystem\.java:82)
	at org\.apache\.hadoop\.fs\.FileSystem\.createFileSystem(FileSystem\.java:1378)
	at org\.apache\.hadoop\.fs\.FileSystem\.access$200(FileSystem\.java:66)
	at org\.apache\.hadoop\.fs\.FileSystem$Cache\.get(FileSystem\.java:1390)
	at org\.apache\.hadoop\.fs\.FileSystem\.get(FileSystem\.java:196)
	at org\.apache\.hadoop\.fs\.FileSystem\.get(FileSystem\.java:95)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:168)
Caused by: java\.io\.EOFException: Detect premature EOF
	at sun\.misc\.Resource\.getBytes(Resource\.java:131)
	at java\.net\.URLClassLoader\.defineClass(URLClassLoader\.java:273)
	at java\.net\.URLClassLoader\.access$000(URLClassLoader\.java:73)
	at java\.net\.URLClassLoader$1\.run(URLClassLoader\.java:212)
	\.\.\. 24 more
" .
Task TASKID="task_201105251513_0166_r_000001" TASK_TYPE="REDUCE" START_TIME="1306385445584" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201105251513_0166_m_000001" TASK_ATTEMPT_ID="attempt_201105251513_0166_m_000001_1" START_TIME="1306384940397" TRACKER_NAME="tracker_damasco\.labbio:localhost/127\.0\.0\.1:47023" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201105251513_0166_m_000001" TASK_ATTEMPT_ID="attempt_201105251513_0166_m_000001_1" TASK_STATUS="SUCCESS" FINISH_TIME="1306384942056" HOSTNAME="/default-rack/damasco\.labbio" STATE_STRING="" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(585)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(143)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(5)][(SPILLED_RECORDS)(Spilled Records)(5)][(MAP_OUTPUT_BYTES)(Map output bytes)(65)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)]}" .
Task TASKID="task_201105251513_0166_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1306385449725" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(585)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(143)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(5)][(SPILLED_RECORDS)(Spilled Records)(5)][(MAP_OUTPUT_BYTES)(Map output bytes)(65)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)]}" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201105251513_0166_r_000001" TASK_ATTEMPT_ID="attempt_201105251513_0166_r_000001_0" START_TIME="1306385445607" TRACKER_NAME="tracker_berlin\.labbio:localhost/127\.0\.0\.1:38958" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201105251513_0166_r_000001" TASK_ATTEMPT_ID="attempt_201105251513_0166_r_000001_0" TASK_STATUS="FAILED" FINISH_TIME="1306385448588" HOSTNAME="berlin\.labbio" ERROR="Error: java\.lang\.ClassNotFoundException: org\.apache\.hadoop\.hdfs\.protocol\.LocatedBlocks
	at java\.net\.URLClassLoader$1\.run(URLClassLoader\.java:214)
	at java\.security\.AccessController\.doPrivileged(Native Method)
	at java\.net\.URLClassLoader\.findClass(URLClassLoader\.java:205)
	at java\.lang\.ClassLoader\.loadClass(ClassLoader\.java:321)
	at sun\.misc\.Launcher$AppClassLoader\.loadClass(Launcher\.java:294)
	at java\.lang\.ClassLoader\.loadClass(ClassLoader\.java:266)
	at java\.lang\.Class\.getDeclaredMethods0(Native Method)
	at java\.lang\.Class\.privateGetDeclaredMethods(Class\.java:2444)
	at java\.lang\.Class\.privateGetPublicMethods(Class\.java:2564)
	at java\.lang\.Class\.getMethods(Class\.java:1427)
	at sun\.misc\.ProxyGenerator\.generateClassFile(ProxyGenerator\.java:426)
	at sun\.misc\.ProxyGenerator\.generateProxyClass(ProxyGenerator\.java:323)
	at java\.lang\.reflect\.Proxy\.getProxyClass(Proxy\.java:518)
	at java\.lang\.reflect\.Proxy\.newProxyInstance(Proxy\.java:598)
	at org\.apache\.hadoop\.ipc\.RPC\.getProxy(RPC\.java:355)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.createRPCNamenode(DFSClient\.java:106)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.<init>(DFSClient\.java:207)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.<init>(DFSClient\.java:170)
	at org\.apache\.hadoop\.hdfs\.DistributedFileSystem\.initialize(DistributedFileSystem\.java:82)
	at org\.apache\.hadoop\.fs\.FileSystem\.createFileSystem(FileSystem\.java:1378)
	at org\.apache\.hadoop\.fs\.FileSystem\.access$200(FileSystem\.java:66)
	at org\.apache\.hadoop\.fs\.FileSystem$Cache\.get(FileSystem\.java:1390)
	at org\.apache\.hadoop\.fs\.FileSystem\.get(FileSystem\.java:196)
	at org\.apache\.hadoop\.fs\.FileSystem\.get(FileSystem\.java:95)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:168)
Caused by: java\.io\.EOFException: Detect premature EOF
	at sun\.misc\.Resource\.getBytes(Resource\.java:131)
	at java\.net\.URLClassLoader\.defineClass(URLClassLoader\.java:273)
	at java\.net\.URLClassLoader\.access$000(URLClassLoader\.java:73)
	at java\.net\.URLClassLoader$1\.run(URLClassLoader\.java:212)
	\.\.\. 24 more
,Error: java\.lang\.ClassNotFoundException: org\.apache\.hadoop\.hdfs\.protocol\.LocatedBlocks
	at java\.net\.URLClassLoader$1\.run(URLClassLoader\.java:214)
	at java\.security\.AccessController\.doPrivileged(Native Method)
	at java\.net\.URLClassLoader\.findClass(URLClassLoader\.java:205)
	at java\.lang\.ClassLoader\.loadClass(ClassLoader\.java:321)
	at sun\.misc\.Launcher$AppClassLoader\.loadClass(Launcher\.java:294)
	at java\.lang\.ClassLoader\.loadClass(ClassLoader\.java:266)
	at java\.lang\.Class\.getDeclaredMethods0(Native Method)
	at java\.lang\.Class\.privateGetDeclaredMethods(Class\.java:2444)
	at java\.lang\.Class\.privateGetPublicMethods(Class\.java:2564)
	at java\.lang\.Class\.getMethods(Class\.java:1427)
	at sun\.misc\.ProxyGenerator\.generateClassFile(ProxyGenerator\.java:426)
	at sun\.misc\.ProxyGenerator\.generateProxyClass(ProxyGenerator\.java:323)
	at java\.lang\.reflect\.Proxy\.getProxyClass(Proxy\.java:518)
	at java\.lang\.reflect\.Proxy\.newProxyInstance(Proxy\.java:598)
	at org\.apache\.hadoop\.ipc\.RPC\.getProxy(RPC\.java:355)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.createRPCNamenode(DFSClient\.java:106)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.<init>(DFSClient\.java:207)
	at org\.apache\.hadoop\.hdfs\.DFSClient\.<init>(DFSClient\.java:170)
	at org\.apache\.hadoop\.hdfs\.DistributedFileSystem\.initialize(DistributedFileSystem\.java:82)
	at org\.apache\.hadoop\.fs\.FileSystem\.createFileSystem(FileSystem\.java:1378)
	at org\.apache\.hadoop\.fs\.FileSystem\.access$200(FileSystem\.java:66)
	at org\.apache\.hadoop\.fs\.FileSystem$Cache\.get(FileSystem\.java:1390)
	at org\.apache\.hadoop\.fs\.FileSystem\.get(FileSystem\.java:196)
	at org\.apache\.hadoop\.fs\.FileSystem\.get(FileSystem\.java:95)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:168)
Caused by: java\.io\.EOFException: Detect premature EOF
	at sun\.misc\.Resource\.getBytes(Resource\.java:131)
	at java\.net\.URLClassLoader\.defineClass(URLClassLoader\.java:273)
	at java\.net\.URLClassLoader\.access$000(URLClassLoader\.java:73)
	at java\.net\.URLClassLoader$1\.run(URLClassLoader\.java:212)
	\.\.\. 24 more
" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201105251513_0166_r_000000" TASK_ATTEMPT_ID="attempt_201105251513_0166_r_000000_0" START_TIME="1306384465894" TRACKER_NAME="tracker_moscou\.labbio:localhost/127\.0\.0\.1:36922" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201105251513_0166_r_000000" TASK_ATTEMPT_ID="attempt_201105251513_0166_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1306384478151" SORT_FINISHED="1306384478581" FINISH_TIME="1306384481760" HOSTNAME="/default-rack/moscou\.labbio" STATE_STRING="reduce > reduce" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(875246)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(875246)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(224780)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(3)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(875252)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(56195)][(SPILLED_RECORDS)(Spilled Records)(59132)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(59132)]}" .
Task TASKID="task_201105251513_0166_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1306385462289" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(875246)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(875246)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(224780)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(3)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(875252)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(56195)][(SPILLED_RECORDS)(Spilled Records)(59132)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(59132)]}" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201105251513_0166_r_000001" TASK_ATTEMPT_ID="attempt_201105251513_0166_r_000001_1" START_TIME="1306384946151" TRACKER_NAME="tracker_damasco\.labbio:localhost/127\.0\.0\.1:47023" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201105251513_0166_r_000001" TASK_ATTEMPT_ID="attempt_201105251513_0166_r_000001_1" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1306384953436" SORT_FINISHED="1306384953771" FINISH_TIME="1306384955943" HOSTNAME="/default-rack/damasco\.labbio" STATE_STRING="reduce > reduce" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(1274106)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(1274106)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(339748)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(3)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(1274112)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(84937)][(SPILLED_RECORDS)(Spilled Records)(84940)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(84940)]}" .
Task TASKID="task_201105251513_0166_r_000001" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1306385464735" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(1274106)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(1274106)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(339748)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(3)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(1274112)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(84937)][(SPILLED_RECORDS)(Spilled Records)(84940)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(84940)]}" .
Task TASKID="task_201105251513_0166_m_000002" TASK_TYPE="CLEANUP" START_TIME="1306385464736" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201105251513_0166_m_000002" TASK_ATTEMPT_ID="attempt_201105251513_0166_m_000002_0" START_TIME="1306384958160" TRACKER_NAME="tracker_damasco\.labbio:localhost/127\.0\.0\.1:47023" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201105251513_0166_m_000002" TASK_ATTEMPT_ID="attempt_201105251513_0166_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1306384959347" HOSTNAME="/default-rack/damasco\.labbio" STATE_STRING="cleanup" COUNTERS="{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)]}" .
Task TASKID="task_201105251513_0166_m_000002" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1306385467739" COUNTERS="{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)]}" .
Job JOBID="job_201105251513_0166" FINISH_TIME="1306385467739" JOB_STATUS="SUCCESS" FINISHED_MAPS="2" FINISHED_REDUCES="2" FAILED_MAPS="1" FAILED_REDUCES="1" COUNTERS="{(org\.apache\.hadoop\.mapred\.JobInProgress$Counter)(Job Counters )[(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(3)][(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(3)][(DATA_LOCAL_MAPS)(Data-local map tasks)(3)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(2149352)][(HDFS_BYTES_READ)(HDFS_BYTES_READ)(21378956)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(4298828)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(564528)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(6)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(144072)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(2149364)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(141132)][(SPILLED_RECORDS)(Spilled Records)(288144)][(MAP_OUTPUT_BYTES)(Map output bytes)(1861196)][(MAP_OUTPUT_RECORDS)(Map output records)(144072)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(144072)]}" .
